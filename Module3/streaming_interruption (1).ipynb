{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c9e547f",
      "metadata": {
        "id": "0c9e547f"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
      "metadata": {
        "id": "319adfec-2d0a-49f2-87f9-275c4a32add2"
      },
      "source": [
        "# Streaming\n",
        "\n",
        "## Review\n",
        "\n",
        "In module 2, covered a few ways to customize graph state and memory.\n",
        "\n",
        "We built up to a Chatbot with external memory that can sustain long-running conversations.\n",
        "\n",
        "## Goals\n",
        "\n",
        "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways.\n",
        "\n",
        "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
      "metadata": {
        "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
      "metadata": {
        "id": "70d7e41b-c6ba-4e47-b645-6c110bede549"
      },
      "source": [
        "## Streaming\n",
        "\n",
        "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b430d92-f595-4322-a56e-06de7485daa8",
      "metadata": {
        "id": "5b430d92-f595-4322-a56e-06de7485daa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4af7ea2-4c9b-4508-e020-48a638c6ff84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0682fc",
      "metadata": {
        "id": "4d0682fc"
      },
      "source": [
        "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
      "metadata": {
        "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
        "outputId": "12c4a18c-769b-47eb-cde1-297f6f6eef1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "# LLM\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# State\n",
        "class State(MessagesState):\n",
        "    summary: str\n",
        "\n",
        "# Define the logic to call the model\n",
        "def call_model(state: State, config: RunnableConfig):\n",
        "\n",
        "    # Get summary if it exists\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # If there is summary, then we add it\n",
        "    if summary:\n",
        "\n",
        "        # Add summary to system message\n",
        "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
        "\n",
        "        # Append summary to any newer messages\n",
        "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "\n",
        "    else:\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "    response = model.invoke(messages, config)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def summarize_conversation(state: State):\n",
        "\n",
        "    # First, we get any existing summary\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # Create our summarization prompt\n",
        "    if summary:\n",
        "\n",
        "        # A summary already exists\n",
        "        summary_message = (\n",
        "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
        "            \"Extend the summary by taking into account the new messages above:\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        summary_message = \"Create a summary of the conversation above:\"\n",
        "\n",
        "    # Add prompt to our history\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Delete all but the 2 most recent messages\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "\n",
        "# Determine whether to end or summarize the conversation\n",
        "def should_continue(state: State):\n",
        "\n",
        "    \"\"\"Return the next node to execute.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # If there are more than four messages, then we summarize the conversation\n",
        "    if len(messages) > 4:\n",
        "        return \"summarize_conversation\"\n",
        "\n",
        "    # Otherwise we can just end\n",
        "    return END\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f847a787-b301-488c-9b58-cba9f389f55d",
      "metadata": {
        "id": "f847a787-b301-488c-9b58-cba9f389f55d"
      },
      "source": [
        "### Streaming full state\n",
        "\n",
        "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "`.stream` and `.astream` are sync and async methods for streaming back results.\n",
        "\n",
        "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
        "\n",
        "* `values`: This streams the full state of the graph after each node is called.\n",
        "* `updates`: This streams updates to the state of the graph after each node is called.\n",
        "\n",
        "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
        "\n",
        "Let's look at `stream_mode=\"updates\"`.\n",
        "\n",
        "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
        "\n",
        "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
      "metadata": {
        "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
        "outputId": "d57317ef-82db-4274-aeb3-844d2808b138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'conversation': {'messages': AIMessage(content='Hello Shan! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CUpH18HT89TiJclqqHcJ5P1pF5rD9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ec6d1426-e7bd-4f74-a90c-6bca987813d2-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
          ]
        }
      ],
      "source": [
        "# Create a thread\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"Hello, I'm Shan!\")]}, config, stream_mode=\"updates\"):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
      "metadata": {
        "id": "0c4882e9-07dd-4d70-866b-dfc530418cad"
      },
      "source": [
        "Let's now just print the state update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c859c777-cb12-4682-9108-6b367e597b81",
      "metadata": {
        "id": "c859c777-cb12-4682-9108-6b367e597b81",
        "outputId": "fbe96991-a79d-4b17-9b60-8869dd4bf287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Shan! How are you doing today? Is there anything specific you'd like to talk about or need help with?\n"
          ]
        }
      ],
      "source": [
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"Hello, I'm Shan!\")]}, config, stream_mode=\"updates\"):\n",
        "    chunk['conversation'][\"messages\"].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "583bf219-6358-4d06-ae99-c40f43569fda",
      "metadata": {
        "id": "583bf219-6358-4d06-ae99-c40f43569fda"
      },
      "source": [
        "Now, we can see `stream_mode=\"values\"`.\n",
        "\n",
        "This is the `full state` of the graph after the `conversation` node is called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
      "metadata": {
        "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
        "outputId": "9ee8eaba-f883-475a-aee8-59b3d4334c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello, I'm Shan!\n",
            "---------------------------------------------------------------------------\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello, I'm Shan!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Shan! How can I assist you today?\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Start conversation, again\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"Hello, I'm Shan!\")\n",
        "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    for m in event['messages']:\n",
        "        m.pretty_print()\n",
        "    print(\"---\"*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
      "metadata": {
        "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7"
      },
      "source": [
        "### Streaming tokens\n",
        "\n",
        "We often want to stream more than graph state.\n",
        "\n",
        "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
        "\n",
        "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
        "\n",
        "Each event is a dict with a few keys:\n",
        "\n",
        "* `event`: This is the type of event that is being emitted.\n",
        "* `name`: This is the name of event.\n",
        "* `data`: This is the data associated with the event.\n",
        "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
        "\n",
        "Let's have a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
      "metadata": {
        "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
        "outputId": "45b895cd-4071-4668-d47b-4200f483ed07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node: . Type: on_chain_start. Name: LangGraph\n",
            "Node: conversation. Type: on_chain_start. Name: conversation\n",
            "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
            "Node: conversation. Type: on_chain_start. Name: should_continue\n",
            "Node: conversation. Type: on_chain_end. Name: should_continue\n",
            "Node: conversation. Type: on_chain_stream. Name: conversation\n",
            "Node: conversation. Type: on_chain_end. Name: conversation\n",
            "Node: . Type: on_chain_stream. Name: LangGraph\n",
            "Node: . Type: on_chain_end. Name: LangGraph\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "input_message = HumanMessage(content=\"My favourite IPL team is Mumbai Indians, give me more information about them please.\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
      "metadata": {
        "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d"
      },
      "source": [
        "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
        "\n",
        "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
        "\n",
        "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
      "metadata": {
        "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
        "outputId": "a32ffb7d-1b57-4848-dbba-c0b4d6074f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='MI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' franchises', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indian', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Premier', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='IPL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=').', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Here', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' key', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' details', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Est', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ablishment', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='200', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' inaugural', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' year', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Ownership', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' owned', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Reli', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ance', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Industries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' through', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' subsidiary', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' India', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Win', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Sports', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' part', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' conglomer', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ate', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Muk', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='esh', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Amb', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ani', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Ground', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ground', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' W', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ank', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='hede', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' seating', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' capacity', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' around', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='33', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='000', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Logo', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' primary', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' blue', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' logo', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' features', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Sud', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ar', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='shan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Chakra', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' symbol', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' power', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' energy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Captain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='cy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Leadership', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Roh', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='it', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Sharma', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' captain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' multiple', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' coaches', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Ma', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='hela', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Jay', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='award', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ene', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Ricky', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Pont', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' past', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Performance', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Ach', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ievements', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' having', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' championship', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Champions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Twenty', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='20', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' twice', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Key', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Over', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' MI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' star', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Sach', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Tend', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ul', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='kar', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Las', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ith', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' M', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='aling', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' K', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ieron', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Poll', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ard', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Jas', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='prit', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Bum', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='rah', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Hard', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ik', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Pand', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ya', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' among', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' others', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Fan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Base', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Culture', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' massive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' support', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' core', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' group', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' focus', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' nurturing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' young', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' talent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Ph', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ilos', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='ophy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Strategy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' MI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' strategic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' approach', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' building', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' focusing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' balanced', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' squad', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' mix', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' experienced', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' young', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' talent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' reputation', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' well', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='-managed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' support', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' staff', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='10', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Community', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Engagement', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' franchise', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' involved', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' various', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' community', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' initiatives', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' social', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' causes', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' education', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' sports', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' development', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' programs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='Mumbai', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' Indians', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' continue', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' be', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' formidable', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' legacy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' commitment', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' excellence', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' off', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content=' field', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad')}\n",
            "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad', chunk_position='last')}\n",
            "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad', usage_metadata={'input_tokens': 23, 'output_tokens': 483, 'total_tokens': 506, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
            "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--b1740ea6-7ddf-44c4-9072-14aa38e4b4ad', chunk_position='last')}\n"
          ]
        }
      ],
      "source": [
        "node_to_stream = 'conversation'\n",
        "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "input_message = HumanMessage(content=\"My favourite IPL team is Mumbai Indians, give me more information about them please.\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        print(event[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
      "metadata": {
        "id": "226e569a-76c3-43d8-8f89-3ae687efde1c"
      },
      "source": [
        "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
      "metadata": {
        "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
        "outputId": "e610b3f3-e2c3-4075-80f1-28452bc6bbc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|The| Mumbai| Indians| (|MI|)| are| a| franchise| cricket| team| based| in| Mumbai|,| Maharashtra|,| that| compet|es| in| the| Indian| Premier| League| (|IPL|).| They| are| one| of| the| most| successful| teams| in| the| league|'s| history| and| have| a| large| fan| following|.\n",
            "\n",
            "|###| Key| Points|:\n",
            "\n",
            "|-| **|Est|ablishment|**|:| The| team| was| founded| in| |200|8|,| the| same| year| the| IPL| was| established|.\n",
            "\n",
            "|-| **|Home| Ground|**|:| The| Mumbai| Indians| play| their| home| matches| at| the| W|ank|hede| Stadium| in| Mumbai|,| which| has| a| seating| capacity| of| around| |33|,|000|.\n",
            "\n",
            "|-| **|Team| Colors| and| Logo|**|:| The| team's| primary| colors| are| blue| and| gold|.| Their| logo| features| the| Sud|ar|shan| Chakra|,| a| symbol| of| power| and| energy|.\n",
            "\n",
            "|-| **|Ownership|**|:| The| team| is| owned| by| Reli|ance| Industries|,| through| its| subsidiary| India|Win| Sports|,| and| is| part| of| the| Reli|ance| Group|,| headed| by| Muk|esh| Amb|ani|.\n",
            "\n",
            "|-| **|Captain| and| Coach|**|:| As| of| the| latest| season|,| the| team| is| capt|ained| by| Roh|it| Sharma|,| who| has| been| instrumental| in| their| success|.| The| head| coach| is| Mark| B|oucher|,| with| Ma|hela| Jay|award|ene| having| served| as| a| successful| coach| in| previous| seasons|.\n",
            "\n",
            "|-| **|Champ|ionship|s|**|:| Mumbai| Indians| have| won| the| IPL| title| five| times| (|201|3|,| |201|5|,| |201|7|,| |201|9|,| and| |202|0|),| making| them| the| most| successful| team| in| the| league|'s| history|.| They| have| also| won| the| Champions| League| Twenty|20| twice|,| in| |201|1| and| |201|3|.\n",
            "\n",
            "|-| **|Not|able| Players|**|:| Over| the| years|,| the| team| has| featured| several| prominent| players|,| including| Sach|in| Tend|ul|kar|,| Las|ith| M|aling|a|,| K|ieron| Poll|ard|,| Jas|prit| Bum|rah|,| and| Hard|ik| Pand|ya|,| among| others|.\n",
            "\n",
            "|-| **|R|ival|ries|**|:| The| Mumbai| Indians| have| a| fierce| rivalry| with| the| Chennai| Super| Kings|,| often| referred| to| as| the| \"|El| Clas|ico|\"| of| the| IPL|.| They| also| have| competitive| rival|ries| with| teams| like| the| Kolkata| Knight| Riders| and| Royal| Chall|engers| Bangalore|.\n",
            "\n",
            "|-| **|Ph|ilos|ophy| and| Culture|**|:| The| team| is| known| for| its| strong| core| group| of| players| and| a| focus| on| nurturing| young| talent|.| They| have| a| reputation| for| being| a| well|-managed| and| strategic| team|,| often| making| smart| decisions| in| player| auctions| and| team| management|.\n",
            "\n",
            "|The| Mumbai| Indians| are| celebrated| for| their| consistent| performances| and| ability| to| perform| under| pressure|,| making| them| a| formidable| team| in| the| IPL|.||||"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
        "input_message = HumanMessage(content=\"My favourite IPL team is Mumbai Indians, give me more information about them please.\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        data = event[\"data\"]\n",
        "        print(data[\"chunk\"].content, end=\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"6\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about another IPL team called Chennai Super Kings.\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        data = event[\"data\"]\n",
        "        print(data[\"chunk\"].content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZNM2NEnaj-v",
        "outputId": "622582be-af67-45bd-8dbe-86346255bf0d"
      },
      "id": "gZNM2NEnaj-v",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|Ch|ennai| Super| Kings| (|CS|K|)| is| one| of| the| most| successful| and| popular| franchises| in| the| Indian| Premier| League| (|IPL|).| The| team| is| based| in| Chennai|,| Tamil| Nadu|,| and| was| founded| in| |200|8| when| the| IPL| was| established|.| Here| are| some| key| details| about| the| Chennai| Super| Kings|:\n",
            "\n",
            "|1|.| **|Ownership| and| Management|**|:| The| team| is| owned| by| Chennai| Super| Kings| Cricket| Ltd|,| with| India| C|ements| being| a| major| stakeholder|.| N|.| Srin|iv|asan|,| the| vice|-chair|man| and| managing| director| of| India| C|ements|,| has| been| a| prominent| figure| associated| with| the| team|.\n",
            "\n",
            "|2|.| **|Home| Ground|**|:| The| home| ground| for| CS|K| is| the| M|.| A|.| Ch|id|amb|aram| Stadium|,| also| known| as| Che|p|auk| Stadium|,| located| in| Chennai|.| The| stadium| is| known| for| its| passionate| fan| base| and| vibrant| atmosphere| during| matches|.\n",
            "\n",
            "|3|.| **|Captain|cy| and| Leadership|**|:| Mah|endra| Singh| Dh|oni|,| one| of| the| most| successful| capt|ains| in| cricket| history|,| has| been| the| face| of| the| franchise| since| its| inception|.| Under| his| leadership|,| CS|K| has| achieved| significant| success| in| the| IPL|.\n",
            "\n",
            "|4|.| **|Co|aching| Staff|**|:| Over| the| years|,| CS|K| has| had| a| strong| coaching| staff|,| with| Stephen| Fleming| serving| as| the| head| coach| for| many| seasons|.| The| team| has| also| had| experienced| support| staff| contributing| to| its| success|.\n",
            "\n",
            "|5|.| **|Performance| and| Ach|ievements|**|:| CS|K| is| one| of| the| most| successful| teams| in| IPL| history|.| As| of| |202|3|,| they| have| won| the| IPL| title| five| times| (|201|0|,| |201|1|,| |201|8|,| |202|1|,| and| |202|3|).| The| team| is| known| for| its| consistency|,| having| reached| the| playoffs| in| most| seasons|.\n",
            "\n",
            "|6|.| **|Team| Composition|**|:| CS|K| has| been| known| for| its| balanced| team| composition|,| often| featuring| a| mix| of| experienced| international| players| and| talented| Indian| cr|ick|eters|.| The| team| has| had| several| iconic| players|,| including| S|ures|h| R|aina|,| Rav|indra| Jade|ja|,| D|wayne| Bravo|,| and| F|af| du| Pl|ess|is|,| among| others|.\n",
            "\n",
            "|7|.| **|Fan| Base| and| Culture|**|:| CS|K| has| a| massive| and| loyal| fan| base|,| often| referred| to| as| the| \"|Yellow| Army|.\"| The| team's| culture| emphasizes| stability|,| experience|,| and| a| calm| approach| to| the| game|,| largely| influenced| by| Dh|oni|'s| leadership| style|.\n",
            "\n",
            "|8|.| **|Challenges|**|:| CS|K| faced| a| significant| challenge| when| they| were| suspended| for| two| years| (|201|6| and| |201|7|)| due| to| a| spot|-f|ixing| scandal|.| However|,| they| made| a| strong| comeback| by| winning| the| title| in| their| return| season| in| |201|8|.\n",
            "\n",
            "|Overall|,| Chennai| Super| Kings| is| a| team| with| a| rich| history|,| a| strong| winning| mentality|,| and| a| significant| impact| on| the| IPL|,| both| on| and| off| the| field|.||||"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streaming with LangGraph API"
      ],
      "metadata": {
        "id": "p9RnGBJWdEOI"
      },
      "id": "p9RnGBJWdEOI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ DISCLAIMER\n",
        "\n",
        "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation here on the local development server and here. To start the local development server, run the following command in your terminal in the /studio directory in this module:\n",
        "\n",
        "langgraph dev\n",
        "You should see the following output:\n",
        "\n",
        "- 🚀 API: http://127.0.0.1:2024\n",
        "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
        "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
        "Open your browser and navigate to the Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024.\n",
        "\n",
        "The LangGraph API supports editing graph state."
      ],
      "metadata": {
        "id": "JMloyq7EdH8i"
      },
      "id": "JMloyq7EdH8i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
      "metadata": {
        "id": "8925b632-512b-48e1-9220-61c06bfbf0b8"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Za-Nskhocox6"
      },
      "id": "Za-Nskhocox6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079c2ad6",
      "metadata": {
        "id": "079c2ad6"
      },
      "outputs": [],
      "source": [
        "from langgraph_sdk import get_client\n",
        "\n",
        "# This is the URL of the local development server\n",
        "URL = \"http://127.0.0.1:2024\"\n",
        "client = get_client(url=URL)\n",
        "\n",
        "# Search all hosted graphs\n",
        "assistants = await client.assistants.search()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
      "metadata": {
        "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32"
      },
      "source": [
        "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
      "metadata": {
        "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
        "outputId": "63142512-6b58-4142-f7b3-7518e2f8bda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "# Input message\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"values\"):\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
      "metadata": {
        "id": "556dc7fd-1cae-404f-816a-f13d772b3b14"
      },
      "source": [
        "The streamed objects have:\n",
        "\n",
        "* `event`: Type\n",
        "* `data`: State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b735aa-139c-45a3-a850-63519c0004f0",
      "metadata": {
        "id": "57b735aa-139c-45a3-a850-63519c0004f0",
        "outputId": "f87315fe-1c0b-4001-ce0d-bf45d5572279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================\n",
            "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
            "=========================\n",
            "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
            "=========================\n",
            "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
            "=========================\n",
            "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
            "=========================\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
        "    messages = event.data.get('messages',None)\n",
        "    if messages:\n",
        "        print(convert_to_messages(messages)[-1])\n",
        "    print('='*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a555d186-27be-4ddf-934c-895a3105035d",
      "metadata": {
        "id": "a555d186-27be-4ddf-934c-895a3105035d"
      },
      "source": [
        "There are some new streaming mode that are only supported via the API.\n",
        "\n",
        "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
        "\n",
        "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
        "\n",
        "All events emitted using `messages` mode have two attributes:\n",
        "\n",
        "* `event`: This is the name of the event\n",
        "* `data`: This is data associated with the event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
      "metadata": {
        "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
        "outputId": "c5b13267-e841-4101-c2e1-2995bbdc8d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metadata\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/complete\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/complete\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"messages\"):\n",
        "    print(event.event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
      "metadata": {
        "id": "8de2f1ea-b232-43fc-af7a-320efce83381"
      },
      "source": [
        "We can see a few events:\n",
        "\n",
        "* `metadata`: metadata about the run\n",
        "* `messages/complete`: fully formed message\n",
        "* `messages/partial`: chat model tokens\n",
        "\n",
        "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
        "\n",
        "Now, let's show how to stream these messages.\n",
        "\n",
        "We'll define a helper function for better formatting of the tool calls in messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
      "metadata": {
        "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
        "outputId": "cd66236e-531b-4a62-fe43-ec8690c84258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
            "Response Metadata: Finish Reason - tool_calls\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "AI: The\n",
            "--------------------------------------------------\n",
            "AI: The result\n",
            "--------------------------------------------------\n",
            "AI: The result of\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is \n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6.\n",
            "--------------------------------------------------\n",
            "AI: The result of multiplying 2 and 3 is 6.\n",
            "Response Metadata: Finish Reason - stop\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "\n",
        "def format_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Format a list of tool calls into a readable string.\n",
        "\n",
        "    Args:\n",
        "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
        "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if tool_calls:\n",
        "        formatted_calls = []\n",
        "        for call in tool_calls:\n",
        "            formatted_calls.append(\n",
        "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
        "            )\n",
        "        return \"\\n\".join(formatted_calls)\n",
        "    return \"No tool calls\"\n",
        "\n",
        "async for event in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input={\"messages\": [input_message]},\n",
        "    stream_mode=\"messages\",):\n",
        "\n",
        "    # Handle metadata events\n",
        "    if event.event == \"metadata\":\n",
        "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Handle partial message events\n",
        "    elif event.event == \"messages/partial\":\n",
        "        for data_item in event.data:\n",
        "            # Process user messages\n",
        "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
        "                print(f\"Human: {data_item['content']}\")\n",
        "            else:\n",
        "                # Extract relevant data from the event\n",
        "                tool_calls = data_item.get(\"tool_calls\", [])\n",
        "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
        "                content = data_item.get(\"content\", \"\")\n",
        "                response_metadata = data_item.get(\"response_metadata\", {})\n",
        "\n",
        "                if content:\n",
        "                    print(f\"AI: {content}\")\n",
        "\n",
        "                if tool_calls:\n",
        "                    print(\"Tool Calls:\")\n",
        "                    print(format_tool_calls(tool_calls))\n",
        "\n",
        "                if invalid_tool_calls:\n",
        "                    print(\"Invalid Tool Calls:\")\n",
        "                    print(format_tool_calls(invalid_tool_calls))\n",
        "\n",
        "                if response_metadata:\n",
        "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
        "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
        "\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
      "metadata": {
        "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}